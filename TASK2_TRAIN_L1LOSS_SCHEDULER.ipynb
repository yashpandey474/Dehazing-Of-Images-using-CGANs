{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashpandey474/CSF425-Deep-Learning-Project-Task-2/blob/master/TASK2_TRAIN_L1LOSS_SCHEDULER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcd2C4DANr-T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "from torch.optim import lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHnL-g8LPQFg",
        "outputId": "f27f7cf7-97b8-419b-e6fb-23a2dd90ee00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6XXrqJqN7Vm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Discriminator\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 1, 4, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        # Perform global average pooling\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return torch.sigmoid(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHNrKmALN7j9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class DehazingDataset(data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        #Get the images\n",
        "        self.root_dir = root_dir\n",
        "        hazy_images_path = os.path.join(root_dir, 'hazy')\n",
        "        clean_images_path = os.path.join(root_dir, 'GT')\n",
        "\n",
        "\n",
        "        self.hazy_images = [os.path.join(hazy_images_path,f) for f in os.listdir(hazy_images_path) if  f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
        "        self.clean_images = [os.path.join(clean_images_path, f) for f in os.listdir(clean_images_path) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
        "\n",
        "        #Filter the images to ensure they are counterparts of the same scene\n",
        "        self.size = len(self.hazy_images)\n",
        "        self.transform=transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hazy_img = self.rgb_loader(self.hazy_images[index])\n",
        "        clean_img = self.rgb_loader(self.clean_images[index])\n",
        "        hazy_img = self.transform(hazy_img)\n",
        "        clean_img = self.transform(clean_img)\n",
        "        return hazy_img, clean_img\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSsmpF47N7mG"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/Task2/Dataset'\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "val_dir = os.path.join(root_dir, 'val')\n",
        "transform = transforms.Compose([\n",
        "                                #  transforms.Resize((224, 224)), # ASSUMING NO NEED FOR RESIZING AS ALL IMAGES ARE ALREADY 256*256\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "                                 ])\n",
        "\n",
        "train_dataset = DehazingDataset(train_dir, transform)\n",
        "val_dataset = DehazingDataset(val_dir, transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bevMWacN7n-"
      },
      "outputs": [],
      "source": [
        "# Define the generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BblKBADFSNLQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the loss function and optimizer\n",
        "bce_loss = nn.BCELoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCfXFtwOwnvT"
      },
      "outputs": [],
      "source": [
        "lr_step_size = 2\n",
        "lr_gamma = 0.5\n",
        "\n",
        "schedulerG = lr_scheduler.StepLR(optimizer_G, lr_step_size, lr_gamma)\n",
        "schedulerD = lr_scheduler.StepLR(optimizer_D, lr_step_size, lr_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycMT2e9VSTnP",
        "outputId": "8c0f3dcd-5a02-4893-a220-2f024bae9be1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "Epoch 1/10:   0%|          | 0/239 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch 1/10:  38%|███▊      | 90/239 [59:45<1:37:59, 39.46s/it]"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    schedulerG.step()\n",
        "    schedulerD.step()\n",
        "\n",
        "    # Initialize total losses for the epoch\n",
        "    g_total_loss = 0\n",
        "    d_total_loss = 0\n",
        "\n",
        "    # Training the generator and discriminator\n",
        "    for hazy_imgs, clean_imgs in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "        # Training the discriminator\n",
        "        discriminator.zero_grad()\n",
        "        real_imgs = clean_imgs\n",
        "\n",
        "        # GENERATOR TAKES HAZY IMAGES AS INPUT\n",
        "        fake_imgs = generator(hazy_imgs)\n",
        "\n",
        "        real_labels = torch.ones(real_imgs.size(0), 1)\n",
        "        fake_labels = torch.zeros(fake_imgs.size(0), 1)\n",
        "\n",
        "        # PREDICTIONS OF DISCRIMINATOR FOR REAL IMAGES\n",
        "        real_outputs = discriminator(real_imgs)\n",
        "\n",
        "        # PREDICTIONS OF DISCRIMINATOR FOR FAKE IMAGES\n",
        "        fake_outputs = discriminator(fake_imgs.detach())\n",
        "\n",
        "        d_loss_real = bce_loss(real_outputs, real_labels)\n",
        "        d_loss_fake = bce_loss(fake_outputs, fake_labels)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # Update discriminator\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Training the generator\n",
        "        generator.zero_grad()\n",
        "        fake_imgs = generator(hazy_imgs)\n",
        "        fake_outputs = discriminator(fake_imgs)\n",
        "        g_loss = bce_loss(fake_outputs, real_labels)\n",
        "\n",
        "        # Compute reconstruction loss\n",
        "        g_res_loss = l1_loss(fake_imgs, clean_imgs)\n",
        "\n",
        "        # Update generator\n",
        "        g_complete_loss = (g_loss + g_res_loss)\n",
        "        g_complete_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Add discriminator and generator losses to total losses\n",
        "        d_total_loss += d_loss.item()\n",
        "        g_total_loss += g_loss.item() + g_res_loss.item()  # Add reconstruction loss to total generator loss\n",
        "\n",
        "    # Print losses\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Generator Loss: {g_total_loss / len(train_dataloader):.4f}, Discriminator Loss: {d_total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Save the trained models\n",
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajYnAQb6S0UB",
        "outputId": "06f67958-ae7e-4021-ce2e-ac7f7ecf24a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8192, 1])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwtngEyUSXb3",
        "outputId": "9d3c831b-0a2c-48aa-cc87-e4db1356e572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 1])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNXLCKmrS8Of",
        "outputId": "70f370cf-9691-4561-eabc-bfe79b252365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8192, 1])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fake_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIABBu14UEbo"
      },
      "outputs": [],
      "source": [
        "#output is 256*32 instead of 32 outputs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmnrKBhK/TAWWwU1sNSAb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}