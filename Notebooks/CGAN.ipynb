{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85c2db3-dbed-4297-af06-dd8696cca9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from database2 import DehazingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2fff1f-37c9-4e61-9842-acccba34b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cfe393-7b59-48cc-b556-8a90f77c53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Task2Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "transform = transforms.Compose([\n",
    "                                #  transforms.Resize((224, 224)), # ASSUMING NO NEED FOR RESIZING AS ALL IMAGES ARE ALREADY 256*256\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                 ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3513c7ef-794d-4ab2-9917-44e2e436ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a748190-d38e-4fed-9c78-dab49eb4c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                       | 0/239 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training the generator and discriminator\n",
    "    for hazy_imgs, clean_imgs in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        real_imgs = clean_imgs\n",
    "\n",
    "        # GENERATOR TAKES HAZY IMAGES AS INPUT\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "\n",
    "        real_labels = torch.ones(real_imgs.size(0), 1)\n",
    "        fake_labels = torch.zeros(fake_imgs.size(0), 1)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR REAL IMAGES\n",
    "        real_outputs = discriminator(real_imgs, hazy_imgs)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR FAKE IMAGES\n",
    "        fake_outputs = discriminator(fake_imgs, hazy_imgs)\n",
    "\n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "        fake_outputs = discriminator(fake_imgs)\n",
    "        g_loss = criterion(fake_outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # Print losses\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Generator Loss: {g_loss.item():.4f}, Discriminator Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "\n",
    "     \n",
    "# Save the trained models\n",
    "torch.save(generator.state_dict(), 'generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427515b-34ff-48de-a12e-3a1cf3c4d658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
