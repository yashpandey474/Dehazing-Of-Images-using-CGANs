{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoMxpD5CDNps"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "from google.colab import drive\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOeStDdIEgWG",
    "outputId": "67d8d984-33fc-4ae1-af3c-c47f66989ddb"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkuxuO8KDjIL"
   },
   "source": [
    "# Function to add haze in varying intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cActxYuDTK7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_haze(image, haze_intensity = \"low\"):\n",
    "    # Convert image to uint8 data type\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Simulate haze by blending the image with a white overlay\n",
    "    overlay = np.full_like(image_uint8, (255, 255, 255), dtype=np.uint8)  # White overlay\n",
    "\n",
    "    # Define range of alpha values based on haze intensity\n",
    "    if haze_intensity == 'low':\n",
    "        # Adjusted alpha range for low haze to make it a little more hazy\n",
    "        alpha_range = (0.2, 0.5)\n",
    "    elif haze_intensity == 'medium':\n",
    "        alpha_range = (0.3, 0.6)\n",
    "    elif haze_intensity == 'high':\n",
    "        alpha_range = (0.6, 0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid haze intensity level. Choose from 'low', 'medium', or 'high'.\")\n",
    "\n",
    "    # Random transparency level within the specified range\n",
    "    alpha = random.uniform(alpha_range[0], alpha_range[1])\n",
    "\n",
    "    # Blend image with overlay to create haze effect\n",
    "    haze_image = cv2.addWeighted(image_uint8, 1 - alpha, overlay, alpha, 0)\n",
    "\n",
    "    return haze_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4ougKj0DmrL"
   },
   "source": [
    "# Function to show clean image along with hazy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jiy-uJdzDVYk"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_images(dataloader, num_images=5, save_path = None):\n",
    "    # Get a batch of data\n",
    "    data_iter = iter(dataloader)\n",
    "    _, images = next(data_iter)\n",
    "\n",
    "    # Plot original clean images\n",
    "    fig, axes = plt.subplots(4, num_images, figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        clean_image = images[i].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        # clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "        clean_image = clean_image * 0.5 + 0.5  # Denormalize and convert to uint8\n",
    "\n",
    "\n",
    "        axes[0, i].imshow(clean_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Clean Image\")\n",
    "\n",
    "        # Add haze at different intensity levels\n",
    "        hazy_image_low = add_haze(clean_image, 'low')\n",
    "        axes[1, i].imshow(hazy_image_low)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Low Haze\")\n",
    "\n",
    "        hazy_image_medium = add_haze(clean_image, 'medium')\n",
    "        axes[2, i].imshow(hazy_image_medium)\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(\"Medium Haze\")\n",
    "\n",
    "        hazy_image_high = add_haze(clean_image, 'high')\n",
    "        axes[3, i].imshow(hazy_image_high)\n",
    "        axes[3, i].axis('off')\n",
    "        axes[3, i].set_title(\"High Haze\")\n",
    "\n",
    "\n",
    "    if save_path:\n",
    "      # Image.fromarray(clean_image).save('clean_image_{i}.png')\n",
    "      Image.fromarray(hazy_image_low).save('hazy_image_low_{i}.png')\n",
    "      Image.fromarray(hazy_image_medium).save('hazy_image_medium_{i}.png')\n",
    "      Image.fromarray(hazy_image_high).save('hazy_image_high_{i}.png')\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # if save_path:\n",
    "    #     plt.savefig(save_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDK_ZbqfDqar"
   },
   "source": [
    "# Load Images into dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJ7Q4gqAEhv4"
   },
   "outputs": [],
   "source": [
    "class DehazingDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        #Get the images\n",
    "        self.root_dir = root_dir\n",
    "        hazy_images_path = os.path.join(root_dir, 'hazy')\n",
    "        clean_images_path = os.path.join(root_dir, 'GT')\n",
    "\n",
    "\n",
    "        hazy_images = [f for f in os.listdir(hazy_images_path) if  f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
    "\n",
    "        self.hazy_images = []\n",
    "        self.clean_images = []\n",
    "\n",
    "        for path in hazy_images:\n",
    "            basename = os.path.splitext(os.path.basename(path))[0]  # Extract base filename without extension\n",
    "            filename = basename.split()[0]\n",
    "\n",
    "            clean_image = os.path.join(clean_images_path, filename + '.png')  # Assuming clean images have PNG extension\n",
    "            if not os.path.exists(clean_image):\n",
    "                clean_image = os.path.join(clean_images_path, filename + '.jpg')  # Try JPG extension\n",
    "            if not os.path.exists(clean_image):\n",
    "                clean_image = os.path.join(clean_images_path, filename + '.jpeg')  # Try JPEG extension\n",
    "            if os.path.exists(clean_image):\n",
    "                self.hazy_images.append(os.path.join(hazy_images_path, path))\n",
    "                self.clean_images.append(clean_image)\n",
    "\n",
    "\n",
    "        self.size = len(self.hazy_images)\n",
    "        self.transform=transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hazy_img = self.rgb_loader(self.hazy_images[index])\n",
    "        clean_img = self.rgb_loader(self.clean_images[index])\n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        clean_img = self.transform(clean_img)\n",
    "        return hazy_img, clean_img\n",
    "\n",
    "    def rgb_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAI3kjjfDqjC"
   },
   "outputs": [],
   "source": [
    "root_dir = '/content/drive/MyDrive/Task2/Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "                                 ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRELzGsGPsC9",
    "outputId": "b638f113-39a5-4e22-a720-f92adf5c23b2"
   },
   "outputs": [],
   "source": [
    "train_dataset.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtMYzsr7VGKz"
   },
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "  image = image.permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        # clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "  image = image * 0.5 + 0.5  # Denormalize and convert to uint8\n",
    "\n",
    "  image = add_haze(image)\n",
    "  Image.fromarray(image).save(f'clean_image_try.png')\n",
    "\n",
    "  plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiUB-lpoN8PQ"
   },
   "source": [
    "# See images & don't save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vhNgDGJ4N_p8",
    "outputId": "97396fe9-fde5-41ce-d8f5-2ac369c50aab"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1ltL_unN58z"
   },
   "source": [
    "# See images and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lg2dS9TMTsLa",
    "outputId": "aebeee0a-cb5b-461b-ba11-87ed42aa0d40"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader, save_path = '/content/drive/MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZYY0MzQ3GaZq",
    "outputId": "3458b78d-5cd6-41ac-c5f3-d3e32a2ac8a9"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader, save_path = '/content/drive/MyDrive/hazy_images_augment_3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDBr3oP6Kr2S"
   },
   "source": [
    "# Actual Augmentation\n",
    "## Read images from a directory, augment and save to respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8mQChbTGvma"
   },
   "outputs": [],
   "source": [
    "def augment_and_save_images(root_dir):\n",
    "    # GET GROUND TRUTH DIRECTORY\n",
    "    input_dir = os.path.join(root_dir, \"GT\")\n",
    "\n",
    "    # GET HAZY DIRECTORY\n",
    "    hazy_dir = os.path.join(root_dir, \"hazy\")\n",
    "\n",
    "    count = 0\n",
    "    for clean_image_path in os.listdir(input_dir):\n",
    "        # LOAD AND PASS TO FUNCTION AS IMAGE\n",
    "        clean_image = Image.open(os.path.join(input_dir, clean_image_path)).convert(\"RGB\")\n",
    "        clean_image = transform(clean_image)\n",
    "\n",
    "        clean_image = clean_image.permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "\n",
    "        # Add haze at different intensity levels\n",
    "        hazy_image_low = add_haze(clean_image, 'low')\n",
    "        hazy_image_medium = add_haze(clean_image, 'medium')\n",
    "\n",
    "        # Save only low haze and medium haze images back to hazy directory\n",
    "        filename = os.path.splitext(os.path.basename(clean_image_path))[0]\n",
    "        Image.fromarray(hazy_image_low).save(os.path.join(hazy_dir, f'{filename} low.png'))\n",
    "        Image.fromarray(hazy_image_medium).save(os.path.join(hazy_dir, f'{filename} medium.png'))\n",
    "\n",
    "        count += 1\n",
    "        print(f\"Augmented {count} Image(s)\")\n",
    "        plt.imshow(hazy_image_low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1oJYhkOEva-"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tjJGCoGMFgb"
   },
   "outputs": [],
   "source": [
    "input_dir = '/content/drive/MyDrive/Task2/Dataset/train/GT'\n",
    "low_haze_dir = '/content/drive/MyDrive/Task2/Dataset/augmented/low_haze'\n",
    "medium_haze_dir = '/content/drive/MyDrive/Task2/Dataset/augmented/medium_haze'\n",
    "root_dir = '/content/drive/MyDrive/Task2/Dataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_-wb_TdOuav"
   },
   "outputs": [],
   "source": [
    "augment_and_save_images(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZdbzzVlY1xF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPqq58uMPM1l"
   },
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4G3d3aINs9j"
   },
   "outputs": [],
   "source": [
    "filename = \"1.png\"\n",
    "image_path = os.path.join(input_dir, filename)\n",
    "clean_image = cv2.imread(image_path)\n",
    "clean_image = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNg_IvSXPvB0"
   },
   "outputs": [],
   "source": [
    "clean_image = Image.open(image_path)\n",
    "clean_image = clean_image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "N_Ov_AZaO-Tr",
    "outputId": "ab39af17-0590-4bd1-a011-3dc2134149ca"
   },
   "outputs": [],
   "source": [
    "plt.imshow(clean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "GVwIuRScPAgC",
    "outputId": "0c56ebd7-d789-4f7d-dddb-fd0f3e5e2059"
   },
   "outputs": [],
   "source": [
    "hazy_image_low = add_haze(clean_image, 'low')\n",
    "plt.imshow(hazy_image_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQii9JnNPIAU",
    "outputId": "ad65e76d-2698-4ff8-f889-09f32316afc5"
   },
   "outputs": [],
   "source": [
    "hazy_image_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1vUfIBwQ7f6",
    "outputId": "b2e521d6-7d00-40bf-97c0-22af01d56f5a"
   },
   "outputs": [],
   "source": [
    "clean_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge_dU4KSQ9ra"
   },
   "outputs": [],
   "source": [
    "hazy_image_low = cv2.cvtColor(hazy_image_low, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSiopscARvtK",
    "outputId": "0680a665-1192-458c-df9c-01e0aabdc991"
   },
   "outputs": [],
   "source": [
    "filename = \"6 clean.jpeg\"\n",
    "basename = os.path.splitext(os.path.basename(filename))[0]  # Extract base filename without extension\n",
    "number_part = basename.split()[0]  # Split the base filename by whitespace and take the first part\n",
    "print(number_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-WNbGuaFh_G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
