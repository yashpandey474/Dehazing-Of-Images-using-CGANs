{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoMxpD5CDNps"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "import imageio\n",
    "from database2 import DehazingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOeStDdIEgWG",
    "outputId": "fb2354d3-03e4-4f6d-e77f-3a17c49d80d1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkuxuO8KDjIL"
   },
   "source": [
    "# Function to add haze in varying intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cActxYuDTK7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_haze(image, haze_intensity = \"low\"):\n",
    "    # Convert image to uint8 data type\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Simulate haze by blending the image with a white overlay\n",
    "    overlay = np.full_like(image_uint8, (255, 255, 255), dtype=np.uint8)  # White overlay\n",
    "\n",
    "    # Define range of alpha values based on haze intensity\n",
    "    if haze_intensity == 'low':\n",
    "        # Adjusted alpha range for low haze to make it a little more hazy\n",
    "        alpha_range = (0.2, 0.5)\n",
    "    elif haze_intensity == 'medium':\n",
    "        alpha_range = (0.3, 0.6)\n",
    "    elif haze_intensity == 'high':\n",
    "        alpha_range = (0.6, 0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid haze intensity level. Choose from 'low', 'medium', or 'high'.\")\n",
    "\n",
    "    # Random transparency level within the specified range\n",
    "    alpha = random.uniform(alpha_range[0], alpha_range[1])\n",
    "\n",
    "    # Blend image with overlay to create haze effect\n",
    "    haze_image = cv2.addWeighted(image_uint8, 1 - alpha, overlay, alpha, 0)\n",
    "\n",
    "    return haze_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4ougKj0DmrL"
   },
   "source": [
    "# Function to show clean image along with hazy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jiy-uJdzDVYk"
   },
   "outputs": [],
   "source": [
    "def show_images(dataloader, num_images=5, save_path = None, save_images = False, save_fig = False):\n",
    "    # Get a batch of data\n",
    "    data_iter = iter(dataloader)\n",
    "    _, images = next(data_iter)\n",
    "\n",
    "    # Plot original clean images\n",
    "    fig, axes = plt.subplots(4, num_images, figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        clean_image = images[i].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        # clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "        clean_image = clean_image * 0.5 + 0.5  # Denormalize and convert to uint8\n",
    "\n",
    "\n",
    "        axes[0, i].imshow(clean_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Clean Image\")\n",
    "\n",
    "        # Add haze at different intensity levels\n",
    "        hazy_image_low = add_haze(clean_image, 'low')\n",
    "        axes[1, i].imshow(hazy_image_low)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Low Haze\")\n",
    "\n",
    "        hazy_image_medium = add_haze(clean_image, 'medium')\n",
    "        axes[2, i].imshow(hazy_image_medium)\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(\"Medium Haze\")\n",
    "\n",
    "        hazy_image_high = add_haze(clean_image, 'high')\n",
    "        axes[3, i].imshow(hazy_image_high)\n",
    "        axes[3, i].axis('off')\n",
    "        axes[3, i].set_title(\"High Haze\")\n",
    "\n",
    "\n",
    "    if save_path and save_images:\n",
    "      # Image.fromarray(clean_image).save('clean_image_{i}.png')\n",
    "      Image.fromarray(hazy_image_low).save('hazy_image_low_{i}.png')\n",
    "      Image.fromarray(hazy_image_medium).save('hazy_image_medium_{i}.png')\n",
    "      Image.fromarray(hazy_image_high).save('hazy_image_high_{i}.png')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path and save_fig:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDK_ZbqfDqar"
   },
   "source": [
    "# Load Images into dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAI3kjjfDqjC"
   },
   "outputs": [],
   "source": [
    "# root_dir = '/content/drive/MyDrive/Task2/Dataset'\n",
    "root_dir = \"Task2Dataset\"\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "                                 ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtMYzsr7VGKz"
   },
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "  image = image.permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        # clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "  image = image * 0.5 + 0.5  # Denormalize and convert to uint8\n",
    "\n",
    "  image = add_haze(image)\n",
    "  Image.fromarray(image).save(f'clean_image_try.png')\n",
    "\n",
    "  plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiUB-lpoN8PQ"
   },
   "source": [
    "# See images & don't save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vhNgDGJ4N_p8",
    "outputId": "97396fe9-fde5-41ce-d8f5-2ac369c50aab"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1ltL_unN58z"
   },
   "source": [
    "# See images and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lg2dS9TMTsLa",
    "outputId": "aebeee0a-cb5b-461b-ba11-87ed42aa0d40"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader, save_path = 'VARYING_HAZE_AUGMENT.png', save_fig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZYY0MzQ3GaZq",
    "outputId": "3458b78d-5cd6-41ac-c5f3-d3e32a2ac8a9"
   },
   "outputs": [],
   "source": [
    "show_images(train_dataloader, save_path = '/content/drive/MyDrive/hazy_images_augment_3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDBr3oP6Kr2S"
   },
   "source": [
    "# Actual Augmentation\n",
    "## Read images from a directory, augment and save to respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8mQChbTGvma"
   },
   "outputs": [],
   "source": [
    "def augment_and_save_images(dataloader, low_haze_dir, medium_haze_dir):\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(low_haze_dir, exist_ok=True)\n",
    "    os.makedirs(medium_haze_dir, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    for _, clean_imgs in dataloader:\n",
    "        for i in range(len(clean_imgs)):\n",
    "            clean_image = clean_imgs[i].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "            clean_image = clean_image * 0.5 + 0.5  # Denormalize\n",
    "\n",
    "            # Add haze at different intensity levels\n",
    "            hazy_image_low = add_haze(clean_image, 'low')\n",
    "            hazy_image_medium = add_haze(clean_image, 'medium')\n",
    "\n",
    "            # Save only low haze and medium haze images\n",
    "            Image.fromarray(hazy_image_low).save(os.path.join(low_haze_dir, f'hazy_image_low_{count}.png'))\n",
    "            Image.fromarray(hazy_image_medium).save(os.path.join(medium_haze_dir, f'hazy_image_medium_{count}.png'))\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            print(f\"AUgmented {count} Image(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tjJGCoGMFgb"
   },
   "outputs": [],
   "source": [
    "input_dir = '/content/drive/MyDrive/Task2/Dataset/train/GT'\n",
    "low_haze_dir = '/content/drive/MyDrive/Task2/Dataset/augmented/low_haze'\n",
    "medium_haze_dir = '/content/drive/MyDrive/Task2/Dataset/augmented/medium_haze'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_-wb_TdOuav",
    "outputId": "b9c8e9bd-2ed9-49d5-8b0b-1d8210740b6f"
   },
   "outputs": [],
   "source": [
    "augment_and_save_images(train_dataloader, low_haze_dir, medium_haze_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "HZBv_NWDMjIg",
    "outputId": "ae7f826b-e009-428d-f92e-4100e0bf410b"
   },
   "outputs": [],
   "source": [
    "clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPqq58uMPM1l"
   },
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4G3d3aINs9j"
   },
   "outputs": [],
   "source": [
    "filename = \"1.png\"\n",
    "image_path = os.path.join(input_dir, filename)\n",
    "clean_image = cv2.imread(image_path)\n",
    "clean_image = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNg_IvSXPvB0"
   },
   "outputs": [],
   "source": [
    "clean_image = Image.open(image_path)\n",
    "clean_image = clean_image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "N_Ov_AZaO-Tr",
    "outputId": "ab39af17-0590-4bd1-a011-3dc2134149ca"
   },
   "outputs": [],
   "source": [
    "plt.imshow(clean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "GVwIuRScPAgC",
    "outputId": "0c56ebd7-d789-4f7d-dddb-fd0f3e5e2059"
   },
   "outputs": [],
   "source": [
    "hazy_image_low = add_haze(clean_image, 'low')\n",
    "plt.imshow(hazy_image_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQii9JnNPIAU",
    "outputId": "ad65e76d-2698-4ff8-f889-09f32316afc5"
   },
   "outputs": [],
   "source": [
    "hazy_image_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1vUfIBwQ7f6",
    "outputId": "b2e521d6-7d00-40bf-97c0-22af01d56f5a"
   },
   "outputs": [],
   "source": [
    "clean_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge_dU4KSQ9ra"
   },
   "outputs": [],
   "source": [
    "hazy_image_low = cv2.cvtColor(hazy_image_low, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSiopscARvtK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
