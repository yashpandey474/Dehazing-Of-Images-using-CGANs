{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GOAL - WRITE MODULAR CODE TO TRAIN MODELS\n",
    "1. Different transforms for clean image, hazy image, test images\n",
    "2. Training using a function with batch size etc as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "from database2 import DehazingDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, down = True, act = 'relu', use_dropout = False):\n",
    "        super(Block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False,padding_mode='reflect')\n",
    "            if down\n",
    "            else\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features,4,2,1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features,features*2,down=True,act='leaky',use_dropout=False)\n",
    "        self.down2 = Block(features*2,features*4,down=True,act='leaky',use_dropout=False)\n",
    "        self.down3 = Block(features*4,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down4 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down5 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down6 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up2 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up3 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up4 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=False)\n",
    "        self.up5 = Block(features*8*2,features*4,down=False,act='relu',use_dropout=False)\n",
    "        self.up6 = Block(features*4*2,features*2,down=False,act='relu',use_dropout=False)\n",
    "        self.up7 = Block(features*2*2,features,down=False,act='relu',use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2,in_channels,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1,d7],dim=1))\n",
    "        up3 = self.up3(torch.cat([up2,d6],dim=1))\n",
    "        up4 = self.up4(torch.cat([up3,d5],dim=1))\n",
    "        up5 = self.up5(torch.cat([up4,d4],dim=1))\n",
    "        up6 = self.up6(torch.cat([up5,d3],dim=1))\n",
    "        up7 = self.up7(torch.cat([up6,d2],dim=1))\n",
    "        return self.final_up(torch.cat([up7,d1],dim=1))\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    model = Generator(in_channels=3, features=64)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, stride = 2):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,4,stride,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels = 3, features = [64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2,features[0],kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        ) # according to paper 64 channel doesn't contain BatchNorm2d\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(CNNBlock(in_channels,feature,stride=1 if feature==features[-1] else 2 ))\n",
    "            in_channels = feature\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode='reflect')\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        x = torch.cat([x,y],dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x, y)\n",
    "    print(model)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO CREATE DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT IN A SEPARATE FILE IF POSSIBLE\n",
    "transform_hazy = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter()], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    \n",
    "])\n",
    "\n",
    "transform_clean = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter()], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# FUNCTIONS TO CREATE DATALOADERS\n",
    "def create_dataloader(directory, batch_size=32, mean=0.5, std=0.5, transform_hazy = None, transform_clean = None):\n",
    "    dataset = DehazingDataset(directory, transform_hazy = transform_hazy, transform_clean = transform_clean)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return dataloader\n",
    "\n",
    "def create_train_val_dataloaders(root_dir, train_batch_size=32, val_batch_size=32, mean=0.5, std=0.5):\n",
    "    train_dir = os.path.join(root_dir, 'train')\n",
    "    val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "    train_dataloader = create_dataloader(train_dir, batch_size=train_batch_size, mean=mean, std=std, transform_hazy = transform_clean, transform_clean = transform_clean)\n",
    "    val_dataloader = create_dataloader(val_dir, batch_size=val_batch_size, mean=mean, std=std, transform_hazy = transform_clean, transform_clean = transform_clean)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../Task2Dataset'\n",
    "train_dataloader, val_dataloader = create_train_val_dataloaders(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, generator, discriminator, train_dataloader, lr_step_size, lr_gamma, lambda_adv=1, lambda_res=150,\n",
    "                 lambda_per=150, lambda_reg = 0.00001, num_epochs=10, wgan=False, n_critic=1, use_l1_loss=True, use_adversarial_loss=True, use_perceptual_loss = True):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.optimizer_G = optim.RMSprop(generator.parameters(), lr=0.00005) if wgan else optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.00005) if wgan else optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.scheduler_G = lr_scheduler.StepLR(self.optimizer_G, lr_step_size, lr_gamma)\n",
    "        self.scheduler_D = lr_scheduler.StepLR(self.optimizer_D, lr_step_size, lr_gamma)\n",
    "        self.criterion_G = nn.BCEWithLogitsLoss()\n",
    "        self.criterion_D = nn.BCEWithLogitsLoss()\n",
    "        self.num_epochs = num_epochs\n",
    "        self.n_critic = n_critic if wgan else 1\n",
    "        self.use_l1_loss = use_l1_loss\n",
    "        self.use_adversarial_loss = use_adversarial_loss\n",
    "        self.use_perceptual_loss = use_perceptual_loss\n",
    "        self.is_wgan = wgan\n",
    "        self.perceptual_loss_net = models.vgg19(pretrained=True).features[:18].eval()\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.lambda_res = lambda_res\n",
    "        self.lambda_per = lambda_per\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.l1loss = nn.L1Loss()\n",
    "        self.l2loss = nn.MSELoss()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(\"Optimizer Summary:\")\n",
    "        print(f\"Generator Optimizer: {self.optimizer_G}\")\n",
    "        print(f\"Discriminator Optimizer: {self.optimizer_D}\")\n",
    "        print(\"Scheduler Summary:\")\n",
    "        print(f\"Generator Scheduler: {self.scheduler_G}\")\n",
    "        print(f\"Discriminator Scheduler: {self.scheduler_D}\")\n",
    "        print(\"Criterion Summary:\")\n",
    "        print(f\"Generator Criterion: {self.criterion_G}\")\n",
    "        print(f\"Discriminator Criterion: {self.criterion_D}\")\n",
    "        print(\"Other Parameters:\")\n",
    "        print(f\"Number of Epochs: {self.num_epochs}\")\n",
    "        print(f\"Number of Critic Updates per Generator Update: {self.n_critic}\")\n",
    "        print(f\"Use L1 Loss: {self.use_l1_loss}\")\n",
    "        print(f\"Use Adversarial Loss: {self.use_adversarial_loss}\")\n",
    "        print(f\"Use Perceptual Loss: {self.use_perceptual_loss}\")\n",
    "        print(f\"Is WGAN: {self.is_wgan}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "\n",
    "    def train(self):\n",
    "        self.print_summary()\n",
    "        epochs = []\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.scheduler_G.step()\n",
    "            self.scheduler_D.step()\n",
    "\n",
    "            g_total_loss = 0\n",
    "            d_total_loss = 0\n",
    "            batch_no = 1\n",
    "\n",
    "            for hazy_imgs, clean_imgs in tqdm(self.train_dataloader, desc=f'Epoch {epoch + 1}/{self.num_epochs}'):\n",
    "                # NON-WGAN TRAINING\n",
    "                if not self.is_wgan:\n",
    "                    g_complete_loss, d_loss, fake_imgs = self.train_step_nonwgan(hazy_imgs, clean_imgs)\n",
    "                    \n",
    "                # WGAN TRAINING\n",
    "                elif self.is_wgan:\n",
    "                    g_complete_loss, d_loss, fake_imgs = self.train_step_wgan(hazy_imgs, clean_imgs)\n",
    "\n",
    "                g_total_loss += g_complete_loss.item()\n",
    "                d_total_loss += d_loss.item()\n",
    "\n",
    "                epochs.append(epoch + batch_no/len(self.train_dataloader))\n",
    "                if self.is_wgan:\n",
    "                    g_losses.append(-g_complete_loss.item())  # Negative because the loss is actually maximized in WGAN.\n",
    "                    d_losses.append(-d_loss.item())\n",
    "                else:\n",
    "                    g_losses.append(g_complete_loss.item())\n",
    "                    d_losses.append(d_loss.item())\n",
    "\n",
    "\n",
    "                if batch_no % 10 == 0:\n",
    "                    self.show_images(hazy_imgs, clean_imgs, fake_imgs, num_images=5)\n",
    "\n",
    "\n",
    "                if batch_no % 20 == 0:\n",
    "                    self.plot_losses(epochs, g_losses, d_losses)\n",
    "\n",
    "                batch_no += 1\n",
    "\n",
    "            g_avg_loss = g_total_loss / len(self.train_dataloader)\n",
    "            d_avg_loss = d_total_loss / len(self.train_dataloader)\n",
    "            print(f\"Epoch [{epoch + 1}/{self.num_epochs}], Generator Avg. Loss: {g_avg_loss:.4f}, Discriminator Avg. Loss: {d_avg_loss:.4f}\")\n",
    "\n",
    "            if (epoch + 1) % 3 == 0:\n",
    "                self.save_samples(epoch)\n",
    "\n",
    "        self.save_models()\n",
    "\n",
    "    def plot_losses(self, epochs, g_losses, d_losses):\n",
    "        plt.plot(epochs, g_losses, label='Generator Loss')\n",
    "        plt.plot(epochs, d_losses, label='Discriminator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Epoch vs. Losses')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def train_step_wgan(self, hazy_imgs, clean_imgs):\n",
    "        real_imgs = clean_imgs\n",
    "        fake_imgs = self.generator(hazy_imgs)\n",
    "                    \n",
    "        for discr_train in range(self.n_critic):\n",
    "            real_outputs = self.discriminator(hazy_imgs, real_imgs)\n",
    "            fake_outputs = self.discriminator(hazy_imgs, fake_imgs.detach())\n",
    "\n",
    "                        \n",
    "            # UPDATE THE DISCRIMINATOR [CRITIC]\n",
    "            self.optimizer_D.zero_grad()\n",
    "                \n",
    "            # WGAN utility, we ascend on this hence the loss will be the negative.\n",
    "            d_loss = -torch.mean(real_outputs - fake_outputs)\n",
    "                \n",
    "            d_loss.backward()\n",
    "            self.optimizer_D.step()\n",
    "                \n",
    "            # CLIPPING OF THE DISCRIMINATOR WEIGHTS\n",
    "            for param in self.discriminator.parameters():\n",
    "                param.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # UPDATE THE GENERATOR\n",
    "        self.optimizer_G.zero_grad()\n",
    "            \n",
    "        # REGENERATE IMAGES AND GET OUTPUTS FROM DISCRIMINATOR\n",
    "        fake_imgs = self.generator(hazy_imgs)\n",
    "        fake_outputs = self.discriminator(hazy_imgs, fake_imgs)\n",
    "            \n",
    "        #  W-LOSS FOR GENERATOR\n",
    "        g_loss = -torch.mean(fake_outputs)\n",
    "        g_loss.backward()\n",
    "                    \n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        return g_loss, d_loss, fake_imgs\n",
    "    \n",
    "\n",
    "    def train_step_nonwgan(self, hazy_imgs, clean_imgs):\n",
    "        # d_loss, g_loss = self.train_step(hazy_imgs.to(self.device), clean_imgs.to(self.device))\n",
    "        self.optimizer_D.zero_grad()\n",
    "        real_imgs = clean_imgs\n",
    "    \n",
    "        # GENERATOR TAKES HAZY IMAGES AS INPUT\n",
    "        fake_imgs = self.generator(hazy_imgs)\n",
    "            \n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR REAL IMAGES\n",
    "        real_outputs = self.discriminator(hazy_imgs, real_imgs)\n",
    "            \n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR FAKE IMAGES\n",
    "        fake_outputs = self.discriminator(hazy_imgs, fake_imgs.detach())\n",
    "            \n",
    "        # CREATE LABELS FOR LOSS CALCULATION\n",
    "        real_labels = torch.ones_like(real_outputs)\n",
    "        fake_labels = torch.zeros_like(fake_outputs)\n",
    "            \n",
    "        d_loss_real = self.criterion_D(real_outputs, real_labels)\n",
    "        d_loss_fake = self.criterion_D(fake_outputs, fake_labels)\n",
    "        d_loss = (d_loss_real + d_loss_fake)/2\n",
    "            \n",
    "        # Update discriminator\n",
    "        d_loss.backward()\n",
    "        self.optimizer_D.step()\n",
    "            \n",
    "        # Training the generator\n",
    "        self.optimizer_G.zero_grad()\n",
    "        fake_imgs = self.generator(hazy_imgs)\n",
    "        fake_outputs = self.discriminator(hazy_imgs, fake_imgs)\n",
    "        g_loss = self.criterion_G(fake_outputs, real_labels)\n",
    "            \n",
    "        # Compute reconstruction loss\n",
    "        g_res_loss = 0\n",
    "        if self.use_l1_loss:\n",
    "            g_res_loss = self.l1loss(fake_imgs, clean_imgs)\n",
    "\n",
    "\n",
    "        g_reg_loss = self.lambda_reg * (\n",
    "            torch.sum(torch.abs(fake_imgs[:, :, :-1, :] - fake_imgs[:, :, 1:, :])) +  # Along height\n",
    "            torch.sum(torch.abs(fake_imgs[:, :, :, :-1] - fake_imgs[:, :, :, 1:]))  # Along width\n",
    "        )\n",
    "\n",
    "        g_l2_loss = self.l2loss(fake_imgs, clean_imgs)\n",
    "            \n",
    "        # Update generator\n",
    "        g_complete_loss = (self.lambda_adv *  g_loss + self.lambda_res * g_res_loss + self.lambda_per * g_l2_loss + g_reg_loss)\n",
    "        g_complete_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        return g_complete_loss, d_loss, fake_imgs\n",
    "\n",
    "    def clamp_discriminator_parameters(self):\n",
    "        for param in self.discriminator.parameters():\n",
    "            param.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "\n",
    "    def save_samples(self, epoch):\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (hazy_imgs, clean_imgs) in enumerate(self.train_dataloader):\n",
    "                fake_imgs = self.generator(hazy_imgs)\n",
    "                fake_imgs = fake_imgs * 0.5 + 0.5\n",
    "                save_image(fake_imgs, f\"sample_{epoch}_batch_{i}.png\")\n",
    "        self.generator.train()\n",
    "\n",
    "\n",
    "    def show_images(self, hazy_imgs, clean_imgs, generated_imgs, num_images=5):\n",
    "        fig, axes = plt.subplots(3, num_images, figsize=(15, 10))\n",
    "        for i in range(num_images):\n",
    "            clean_image = clean_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "            hazy_image = hazy_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "            generated_image = generated_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "    \n",
    "            clean_image = clean_image * 0.5 + 0.5\n",
    "            hazy_image = hazy_image * 0.5 + 0.5\n",
    "            generated_image = generated_image * 0.5 + 0.5\n",
    "    \n",
    "            \n",
    "            # Plot hazy images\n",
    "            axes[0, i].imshow(hazy_image)\n",
    "            axes[0, i].axis('off')\n",
    "            axes[0, i].set_title(\"Hazy Image\")\n",
    "    \n",
    "            # Plot clean images\n",
    "            axes[1, i].imshow(clean_image)\n",
    "            axes[1, i].axis('off')\n",
    "            axes[1, i].set_title(\"Clean Image\")\n",
    "    \n",
    "            # Plot generated images\n",
    "            axes[2, i].imshow(generated_image)\n",
    "            axes[2, i].axis('off')\n",
    "            axes[2, i].set_title(\"Generated Image\")\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_models(self):\n",
    "        torch.save(self.generator.state_dict(), 'generator.pth')\n",
    "        torch.save(self.discriminator.state_dict(), 'discriminator.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Generator and Discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Create Trainer instance and train\n",
    "lr_step_size = 2\n",
    "lr_gamma = 0.5\n",
    "trainer = Trainer(generator, discriminator, train_dataloader, lr_step_size, lr_gamma)\n",
    "trainer.train()\n",
    "\n",
    "# lambda_adv=1, lambda_res=150,\n",
    "# lambda_per=150, num_epochs=10, wgan=False, n_critic=0, use_l1_loss=True, use_adversarial_loss=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'generator_cgan_wgan.pth')\n",
    "# torch.save(self.discriminator.state_dict(), 'discriminator.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# ADDING PERCEPTUAL LOSS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
