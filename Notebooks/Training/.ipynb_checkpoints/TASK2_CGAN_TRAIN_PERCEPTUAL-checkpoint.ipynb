{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pcd2C4DANr-T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "from database2 import DehazingDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupyterthemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, down = True, act = 'relu', use_dropout = False):\n",
    "        super(Block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False,padding_mode='reflect')\n",
    "            if down\n",
    "            else\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features,4,2,1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features,features*2,down=True,act='leaky',use_dropout=False)\n",
    "        self.down2 = Block(features*2,features*4,down=True,act='leaky',use_dropout=False)\n",
    "        self.down3 = Block(features*4,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down4 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down5 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down6 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up2 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up3 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up4 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=False)\n",
    "        self.up5 = Block(features*8*2,features*4,down=False,act='relu',use_dropout=False)\n",
    "        self.up6 = Block(features*4*2,features*2,down=False,act='relu',use_dropout=False)\n",
    "        self.up7 = Block(features*2*2,features,down=False,act='relu',use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2,in_channels,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1,d7],dim=1))\n",
    "        up3 = self.up3(torch.cat([up2,d6],dim=1))\n",
    "        up4 = self.up4(torch.cat([up3,d5],dim=1))\n",
    "        up5 = self.up5(torch.cat([up4,d4],dim=1))\n",
    "        up6 = self.up6(torch.cat([up5,d3],dim=1))\n",
    "        up7 = self.up7(torch.cat([up6,d2],dim=1))\n",
    "        return self.final_up(torch.cat([up7,d1],dim=1))\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    model = Generator(in_channels=3, features=64)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLER VERSION OF REPO GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act='relu'):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect') if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == 'relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features*2, down=True)\n",
    "        self.down2 = Block(features*2, features*4, down=True)\n",
    "        self.down3 = Block(features*4, features*8, down=True)\n",
    "        self.down4 = Block(features*8, features*8, down=True)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8, features*8, down=False)\n",
    "        self.up2 = Block(features*8*2, features*8, down=False)\n",
    "        self.up3 = Block(features*8*2, features*4, down=False)\n",
    "        self.up4 = Block(features*4*2, features*2, down=False)\n",
    "        self.up5 = Block(features*2*2, features, down=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        bottleneck = self.bottleneck(d5)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d5], dim=1))\n",
    "        up3 = self.up3(torch.cat([up2, d4], dim=1))\n",
    "        up4 = self.up4(torch.cat([up3, d3], dim=1))\n",
    "        up5 = self.up5(torch.cat([up4, d2], dim=1))\n",
    "        return self.final_up(torch.cat([up5, d1], dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, stride = 2):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,4,stride,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels = 3, features = [64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2,features[0],kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        ) # according to paper 64 channel doesn't contain BatchNorm2d\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(CNNBlock(in_channels,feature,stride=1 if feature==features[-1] else 2 ))\n",
    "            in_channels = feature\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode='reflect')\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        x = torch.cat([x,y],dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x, y)\n",
    "    print(model)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSsmpF47N7mG"
   },
   "outputs": [],
   "source": [
    "root_dir = '../Task2Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),   \n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5],std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(hazy_imgs, clean_imgs, generated_imgs, num_images=5):\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        clean_image = clean_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        hazy_image = hazy_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        generated_image = generated_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "\n",
    "        clean_image = clean_image * 0.5 + 0.5\n",
    "        hazy_image = hazy_image * 0.5 + 0.5\n",
    "        generated_image = generated_image * 0.5 + 0.5\n",
    "\n",
    "        \n",
    "        # Plot hazy images\n",
    "        axes[0, i].imshow(hazy_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Hazy Image\")\n",
    "\n",
    "        # Plot clean images\n",
    "        axes[1, i].imshow(clean_image)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Clean Image\")\n",
    "\n",
    "        # Plot generated images\n",
    "        axes[2, i].imshow(generated_image)\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(\"Generated Image\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bevMWacN7n-"
   },
   "outputs": [],
   "source": [
    "# Define the generator and discriminator\n",
    "generator = SimpleGenerator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "lr_step_size = 2\n",
    "lr_gamma = 0.5\n",
    "\n",
    "schedulerG = lr_scheduler.StepLR(optimizer_G, lr_step_size, lr_gamma)\n",
    "schedulerD = lr_scheduler.StepLR(optimizer_D, lr_step_size, lr_gamma)\n",
    "\n",
    "perceptual_loss_net = vgg19(pretrained=True).features[:18].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycMT2e9VSTnP",
    "outputId": "8c0f3dcd-5a02-4893-a220-2f024bae9be1"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    batch_no = 0\n",
    "    schedulerG.step()\n",
    "    schedulerD.step()\n",
    "\n",
    "    # Initialize total losses for the epoch\n",
    "    g_total_loss = 0\n",
    "    d_total_loss = 0\n",
    "\n",
    "    # Training the generator and discriminator\n",
    "    for hazy_imgs, clean_imgs in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        real_imgs = cleaen_imgs\n",
    "\n",
    "        # GENERATOR TAKES HAZY IMAGES AS INPUT\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR REAL IMAGES\n",
    "        real_outputs = discriminator(hazy_imgs, real_imgs)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR FAKE IMAGES\n",
    "        fake_outputs = discriminator(hazy_imgs, fake_imgs.detach())\n",
    "\n",
    "        # CREATE LABELS FOR LOSS CALCULATION\n",
    "        real_labels = torch.ones_like(real_outputs)\n",
    "        fake_labels = torch.zeros_like(fake_outputs)\n",
    "\n",
    "        d_loss_real = bce_loss(real_outputs, real_labels)\n",
    "        d_loss_fake = bce_loss(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # Update discriminator\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "        fake_outputs = discriminator(hazy_imgs, fake_imgs)\n",
    "        g_loss = bce_loss(fake_outputs, real_labels)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        g_res_loss = l1_loss(fake_imgs, clean_imgs)\n",
    "\n",
    "        # Update generator\n",
    "        g_complete_loss = (g_loss + g_res_loss)\n",
    "        g_complete_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        batch_no += 1\n",
    "\n",
    "        if batch_no % 20 == 0:\n",
    "            show_images(hazy_imgs, clean_imgs, fake_imgs, num_images=5)\n",
    "            \n",
    "\n",
    "    # Print losses\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Generator Loss: {g_total_loss / len(train_dataloader):.4f}, Discriminator Loss: {d_total_loss / len(train_dataloader):.4f}\")\n",
    "\n",
    "# Save the trained models\n",
    "torch.save(generator.state_dict(), 'generator_l1_cgan_simple.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator_l1_cgan_simple.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'generator_l1_cgan.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator_l1_cgan.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(hazy_imgs, clean_imgs, fake_imgs, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_images(clean_imgs, num_images=5):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        clean_image = clean_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        clean_image = clean_image * 0.5 + 0.5\n",
    "\n",
    "        # Plot clean images\n",
    "        axes[i].imshow(clean_image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(\"Clean Image\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, clean_imgs in train_dataloader:\n",
    "    show_one_images(clean_imgs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one_images(fake_imgs, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Hazy/Generated/Clean images pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE AND LOAD WEIGHTS TO A GENERATOR\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "weights_path = 'generator_l1_cgan.pth'\n",
    "\n",
    "# Load the weights into the generator model\n",
    "generator.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "# Set the generator to evaluation mode\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE AND LOAD WEIGHTS TO A GENERATOR\n",
    "\n",
    "discriminator = Discriminator()\n",
    "\n",
    "weights_path = 'discriminator_l1_cgan.pth'\n",
    "\n",
    "# Load the weights into the generator model\n",
    "discriminator.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "# Set the generator to evaluation mode\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate hazy/generated/clean pairs from val dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hazy_imgs, clean_imgs in val_dataloader:\n",
    "    generated_imgs = generator(hazy_imgs)\n",
    "    show_images(hazy_imgs, clean_imgs, generated_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
