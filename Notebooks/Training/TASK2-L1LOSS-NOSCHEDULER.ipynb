{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "from database2 import DehazingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        # Perform global average pooling\n",
    "        x = torch.mean(x, dim=(2, 3))\n",
    "        return torch.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Task2Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "transform = transforms.Compose([\n",
    "                                #  transforms.Resize((224, 224)), # ASSUMING NO NEED FOR RESIZING AS ALL IMAGES ARE ALREADY 256*256\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                 ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "bce_loss = nn.BCELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # schedulerG.step()\n",
    "    # schedulerD.step()\n",
    "\n",
    "    # Initialize total losses for the epoch\n",
    "    g_total_loss = 0\n",
    "    d_total_loss = 0\n",
    "\n",
    "    # Training the generator and discriminator\n",
    "    for hazy_imgs, clean_imgs in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        real_imgs = clean_imgs\n",
    "\n",
    "        # GENERATOR TAKES HAZY IMAGES AS INPUT\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "\n",
    "        real_labels = torch.ones(real_imgs.size(0), 1)\n",
    "        fake_labels = torch.zeros(fake_imgs.size(0), 1)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR REAL IMAGES\n",
    "        real_outputs = discriminator(real_imgs)\n",
    "\n",
    "        # PREDICTIONS OF DISCRIMINATOR FOR FAKE IMAGES\n",
    "        fake_outputs = discriminator(fake_imgs.detach())\n",
    "\n",
    "        d_loss_real = bce_loss(real_outputs, real_labels)\n",
    "        d_loss_fake = bce_loss(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # Update discriminator\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        fake_imgs = generator(hazy_imgs)\n",
    "        fake_outputs = discriminator(fake_imgs)\n",
    "        g_loss = bce_loss(fake_outputs, real_labels)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        g_res_loss = l1_loss(fake_imgs, clean_imgs)\n",
    "\n",
    "        # Update generator\n",
    "        g_complete_loss = (g_loss + g_res_loss)\n",
    "        g_complete_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Add discriminator and generator losses to total losses\n",
    "        d_total_loss += d_loss.item()\n",
    "        g_total_loss += g_loss.item() + g_res_loss.item()  # Add reconstruction loss to total generator loss\n",
    "\n",
    "    # Print losses\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Generator Loss: {g_total_loss / len(train_dataloader):.4f}, Discriminator Loss: {d_total_loss / len(train_dataloader):.4f}\")\n",
    "\n",
    "# Save the trained models\n",
    "torch.save(generator.state_dict(), 'generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'generator_l1loss_noscheduler.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator_l1loss_noscheduler.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "generated_images = generator(hazy_imgs[:num_samples]).detach().cpu()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    plt.imshow(hazy_imgs[i].permute(1, 2, 0))  # Assuming images are in CHW format\n",
    "    plt.title('Hazy Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, num_samples, num_samples + i + 1)\n",
    "    plt.imshow(generated_images[i].permute(1, 2, 0))  # Assuming images are in CHW format\n",
    "    plt.title('Generated Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
