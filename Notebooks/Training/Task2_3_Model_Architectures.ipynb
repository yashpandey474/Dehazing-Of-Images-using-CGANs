{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFKeOL86io5W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JB0oPjait9k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUN632MTit_n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m4wuFB8iuB2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btK9hK4_iuI0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfIoj1TMi2Xs"
   },
   "source": [
    "# Sample Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4F-lU9Ygi8R3"
   },
   "outputs": [],
   "source": [
    "# GPT -> BASIC\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, img_size * img_size * channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.cat((noise, labels), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), channels, img_size, img_size)\n",
    "        return img\n",
    "\n",
    "# GPT -> BASIC\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size * channels + num_classes, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        d_in = torch.cat((img_flat, labels), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VF2-UbZoiuLJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# GITHUB - https://github.com/hieubkset/pytorch-image-dehazing/blob/master/model.py\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        haze_class = models.densenet121(pretrained=True)\n",
    "\n",
    "        ############# Block0-down  ##############\n",
    "        self.conv0 = haze_class.features.conv0\n",
    "        self.relu0 = haze_class.features.relu0\n",
    "        self.pool0 = haze_class.features.pool0\n",
    "\n",
    "        ############# Block1-down ##############\n",
    "        self.dense_block1 = haze_class.features.denseblock1\n",
    "        self.trans_block1 = haze_class.features.transition1\n",
    "\n",
    "        ############# Block2-down ##############\n",
    "        self.dense_block2 = haze_class.features.denseblock2\n",
    "        self.trans_block2 = haze_class.features.transition2\n",
    "\n",
    "        ############# Block3-down ##############\n",
    "        self.dense_block3 = haze_class.features.denseblock3\n",
    "        self.trans_block3 = haze_class.features.transition3\n",
    "        self.res31 = BasicResBlock(512, 512)\n",
    "        self.res32 = BasicResBlock(512, 512)\n",
    "\n",
    "        ############# Block4-up ##############\n",
    "        self.dense_block4 = BottleneckBlock(512, 256)\n",
    "        self.trans_block4 = TransitionBlock(768, 128)\n",
    "        self.res41 = BasicResBlock(387, 387)\n",
    "        self.res42 = BasicResBlock(387, 387)\n",
    "\n",
    "        ############# Block3-up ##############\n",
    "        self.dense_block5 = BottleneckBlock(387, 256)\n",
    "        self.trans_block5 = TransitionBlock(643, 128)\n",
    "        self.res51 = BasicResBlock(259, 259)\n",
    "        self.res52 = BasicResBlock(259, 259)\n",
    "\n",
    "        ############# Block2-up ##############\n",
    "        self.dense_block6 = BottleneckBlock(259, 128)\n",
    "        self.trans_block6 = TransitionBlock(387, 64)\n",
    "        self.res61 = BasicResBlock(67, 67)\n",
    "        self.res62 = BasicResBlock(67, 67)\n",
    "\n",
    "        ############# Block1-up ##############\n",
    "        self.dense_block7 = BottleneckBlock(67, 64)\n",
    "        self.trans_block7 = TransitionBlock(131, 32)\n",
    "        self.res71 = BasicResBlock(35, 35)\n",
    "        self.res72 = BasicResBlock(35, 35)\n",
    "\n",
    "        ############# Block0-up ##############\n",
    "        self.dense_block8 = BottleneckBlock(35, 32)\n",
    "        self.trans_block8 = TransitionBlock(67, 16)\n",
    "\n",
    "        # multi-scale\n",
    "        self.conv_refin = nn.Conv2d(19, 20, 3, 1, 1)\n",
    "        self.refout = nn.Conv2d(20, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## input: 1024 x 1024\n",
    "\n",
    "        x0 = self.pool0(self.relu0(self.conv0(x)))  # 256 x 256\n",
    "\n",
    "        x1 = self.dense_block1(x0)  # 256 x 256\n",
    "\n",
    "        x1 = self.trans_block1(x1)  # 128 x 128\n",
    "\n",
    "        x2 = self.trans_block2(self.dense_block2(x1))  # 64 x 64\n",
    "\n",
    "        x3 = self.trans_block3(self.dense_block3(x2))  # 32 x 32\n",
    "        x3 = self.res31(x3)  # 32 x 32\n",
    "        x3 = self.res32(x3)  # 32 x 32\n",
    "\n",
    "        x4 = self.trans_block4(self.dense_block4(x3))  # 64 x 64\n",
    "        x43 = F.avg_pool2d(x, 16)  # 64 x 64\n",
    "        x42 = torch.cat([x4, x2, x43], 1)  # 64 x 64\n",
    "        x42 = self.res41(x42)  # 64\n",
    "        x42 = self.res42(x42)  # 64\n",
    "\n",
    "        x5 = self.trans_block5(self.dense_block5(x42))  # 128\n",
    "        x53 = F.avg_pool2d(x, 8)  # 128\n",
    "        x52 = torch.cat([x5, x1, x53], 1)  # 128\n",
    "        x52 = self.res51(x52)  # 128\n",
    "        x52 = self.res52(x52)  # 128\n",
    "\n",
    "        x6 = self.trans_block6(self.dense_block6(x52))  # 256\n",
    "        x63 = F.avg_pool2d(x, 4)  # 256\n",
    "        x62 = torch.cat([x6, x63], 1)  # 256\n",
    "        x62 = self.res61(x62)  # 256\n",
    "        x6 = self.res62(x62)  # 256\n",
    "\n",
    "        x7 = self.trans_block7(self.dense_block7(x6))  # 512\n",
    "        x73 = F.avg_pool2d(x, 2)  # 512\n",
    "        x72 = torch.cat([x7, x73], 1)  # 512\n",
    "        x72 = self.res71(x72)  # 512\n",
    "        x7 = self.res72(x72)  # 512\n",
    "\n",
    "        x8 = self.trans_block8(self.dense_block8(x7))  # 1024\n",
    "        x8 = torch.cat([x8, x], 1)  # 1024\n",
    "\n",
    "        x9 = self.relu(self.conv_refin(x8))  # 1024\n",
    "\n",
    "        dehaze = self.tanh(self.refout(x9))\n",
    "\n",
    "        return dehaze\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        inter_planes = out_planes * 4\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n",
    "                               padding=0, bias=False)\n",
    "        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(x))\n",
    "        out = self.conv2(self.relu(out))\n",
    "        return torch.cat([x, out], 1)\n",
    "\n",
    "\n",
    "class TransitionBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(TransitionBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.ConvTranspose2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
    "                                        padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(x))\n",
    "        return F.interpolate(out, scale_factor=2)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicResBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes):\n",
    "        super(BasicResBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, nf=36):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, nf, kernel_size=4, stride=2, padding=1, bias=False),  # 36 x 512 x 512\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            DBlock(nf, nf * 2),  # 72 x 256 x 256\n",
    "            DBlock(nf * 2, nf * 4),  # 144 x 128 x 128\n",
    "            DBlock(nf * 4, nf * 8),  # 288 x 64 x 64\n",
    "            DBlock(nf * 8, nf * 8),  # 288 x 32 x 632\n",
    "            nn.Conv2d(nf * 8, nf * 8, 4, 1, 1, bias=False),  # 288 x 31 x 31\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(nf * 8, 1, 4, 1, 1, bias=False),  # 288 x 30 x 30\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output\n",
    "\n",
    "    def requires_grad(self, req):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = req\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super(DBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04IdL5S5jQUS"
   },
   "outputs": [],
   "source": [
    "# GPT -> ENCODER-DECODER\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, num_classes, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# GPT -> PATCHGAN\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjA1wnM2jZUk"
   },
   "outputs": [],
   "source": [
    "# GPT -> UNET\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 1024, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, out_channels, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x = self.decoder(x1)\n",
    "        return x\n",
    "\n",
    "# GPT -> PATCH GAN\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, stride, normalize):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride, 1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, 2, False),\n",
    "            *discriminator_block(64, 128, 2, True),\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZiMMyRJiuk3"
   },
   "source": [
    "# Sample Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uqyr0pBiywF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(args):\n",
    "    print(args)\n",
    "\n",
    "    # net\n",
    "    netG = Generator()\n",
    "    netG = netG.cuda()\n",
    "    netD = Discriminator()\n",
    "    netD = netD.cuda()\n",
    "\n",
    "    # loss\n",
    "    l1_loss = nn.L1Loss().cuda()\n",
    "    l2_loss = nn.MSELoss().cuda()\n",
    "    bce_loss = nn.BCELoss().cuda()\n",
    "\n",
    "    # opt\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=args.glr)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=args.dlr)\n",
    "\n",
    "    # lr\n",
    "    schedulerG = lr_scheduler.StepLR(optimizerG, args.lr_step_size, args.lr_gamma)\n",
    "    schedulerD = lr_scheduler.StepLR(optimizerD, args.lr_step_size, args.lr_gamma)\n",
    "\n",
    "    # utility for saving models, parameters and logs\n",
    "    save = SaveData(args.save_dir, args.exp, True)\n",
    "    save.save_params(args)\n",
    "\n",
    "    # netG, _ = save.load_model(netG)\n",
    "\n",
    "    dataset = MyDataset(args.data_dir, is_train=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                             num_workers=int(args.n_threads))\n",
    "\n",
    "    real_label = Variable(torch.ones([1, 1, args.patch_gan, args.patch_gan], dtype=torch.float)).cuda()\n",
    "    fake_label = Variable(torch.zeros([1, 1, args.patch_gan, args.patch_gan], dtype=torch.float)).cuda()\n",
    "\n",
    "    image_pool = ImagePool(args.pool_size)\n",
    "\n",
    "    vgg = Vgg16(requires_grad=False)\n",
    "    vgg.cuda()\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        print(\"* Epoch {}/{}\".format(epoch + 1, args.epochs))\n",
    "\n",
    "        schedulerG.step()\n",
    "        schedulerD.step()\n",
    "\n",
    "        d_total_real_loss = 0\n",
    "        d_total_fake_loss = 0\n",
    "        d_total_loss = 0\n",
    "\n",
    "        g_total_res_loss = 0\n",
    "        g_total_per_loss = 0\n",
    "        g_total_gan_loss = 0\n",
    "        g_total_loss = 0\n",
    "\n",
    "        netG.train()\n",
    "        netD.train()\n",
    "\n",
    "        for batch, images in tqdm(enumerate(dataloader)):\n",
    "            input_image, target_image = images\n",
    "            input_image = Variable(input_image.cuda())\n",
    "            target_image = Variable(target_image.cuda())\n",
    "            output_image = netG(input_image)\n",
    "\n",
    "            # Update D\n",
    "            netD.requires_grad(True)\n",
    "            netD.zero_grad()\n",
    "\n",
    "            ## real image\n",
    "            real_output = netD(target_image)\n",
    "            d_real_loss = bce_loss(real_output, real_label)\n",
    "            d_real_loss.backward()\n",
    "            d_real_loss = d_real_loss.data.cpu().numpy()\n",
    "            d_total_real_loss += d_real_loss\n",
    "\n",
    "            ## fake image\n",
    "            fake_image = output_image.detach()\n",
    "            fake_image = Variable(image_pool.query(fake_image.data))\n",
    "            fake_output = netD(fake_image)\n",
    "            d_fake_loss = bce_loss(fake_output, fake_label)\n",
    "            d_fake_loss.backward()\n",
    "            d_fake_loss = d_fake_loss.data.cpu().numpy()\n",
    "            d_total_fake_loss += d_fake_loss\n",
    "\n",
    "            ## loss\n",
    "            d_total_loss += d_real_loss + d_fake_loss\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Update G\n",
    "            netD.requires_grad(False)\n",
    "            netG.zero_grad()\n",
    "\n",
    "            ## reconstruction loss\n",
    "            g_res_loss = l1_loss(output_image, target_image)\n",
    "            g_res_loss.backward(retain_graph=True)\n",
    "            g_res_loss = g_res_loss.data.cpu().numpy()\n",
    "            g_total_res_loss += g_res_loss\n",
    "\n",
    "            ## perceptual loss\n",
    "            g_per_loss = args.p_factor * l2_loss(vgg(output_image), vgg(target_image))\n",
    "            g_per_loss.backward(retain_graph=True)\n",
    "            g_per_loss = g_per_loss.data.cpu().numpy()\n",
    "            g_total_per_loss += g_per_loss\n",
    "\n",
    "            ## gan loss\n",
    "            output = netD(output_image)\n",
    "            g_gan_loss = args.g_factor * bce_loss(output, real_label)\n",
    "            g_gan_loss.backward()\n",
    "            g_gan_loss = g_gan_loss.data.cpu().numpy()\n",
    "            g_total_gan_loss += g_gan_loss\n",
    "\n",
    "            ## loss\n",
    "            g_total_loss += g_res_loss + g_per_loss + g_gan_loss\n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "        d_total_real_loss = d_total_real_loss / (batch + 1)\n",
    "        d_total_fake_loss = d_total_fake_loss / (batch + 1)\n",
    "        d_total_loss = d_total_loss / (batch + 1)\n",
    "        save.add_scalar('D/real', d_total_real_loss, epoch)\n",
    "        save.add_scalar('D/fake', d_total_fake_loss, epoch)\n",
    "        save.add_scalar('D/total', d_total_loss, epoch)\n",
    "\n",
    "        g_total_res_loss = g_total_res_loss / (batch + 1)\n",
    "        g_total_per_loss = g_total_per_loss / (batch + 1)\n",
    "        g_total_gan_loss = g_total_gan_loss / (batch + 1)\n",
    "        g_total_loss = g_total_loss / (batch + 1)\n",
    "        save.add_scalar('G/res', g_total_res_loss, epoch)\n",
    "        save.add_scalar('G/per', g_total_per_loss, epoch)\n",
    "        save.add_scalar('G/gan', g_total_gan_loss, epoch)\n",
    "        save.add_scalar('G/total', g_total_loss, epoch)\n",
    "\n",
    "        if epoch % args.period == 0:\n",
    "            log = \"Train d_loss: {:.5f} \\t g_loss: {:.5f}\".format(d_total_loss, g_total_loss)\n",
    "            print(log)\n",
    "            save.save_log(log)\n",
    "            save.save_model(netG, epoch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKe40W40iwCp"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "latent_dim = 100\n",
    "num_classes = 10\n",
    "img_size = 28\n",
    "channels = 1\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Define loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Initialize optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1)\n",
    "        fake = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        labels = Variable(labels.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "        gen_labels = Variable(Tensor(np.random.randint(0, num_classes, imgs.shape[0])))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_pred = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        fake_pred = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
