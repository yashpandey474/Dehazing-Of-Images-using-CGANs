{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7IvjVTHRZpO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2u6WUPQS41o",
    "outputId": "6a03a3ea-eeb0-4153-98a4-1d03a942fb86"
   },
   "outputs": [],
   "source": [
    "# MOUNT GOOGLE DRIVE\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS8nx5QgSSXQ"
   },
   "source": [
    "# Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0maaKg6SRop"
   },
   "outputs": [],
   "source": [
    "CUDA=True\n",
    "DATA_PATH = './data'\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNEL = 1\n",
    "Z_DIM = 100\n",
    "gener_hidden = 64\n",
    "X_DIM = 64\n",
    "discrm_hidden = 64\n",
    "EPOCH_NUM = 5\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NH2Er7tRbNp"
   },
   "outputs": [],
   "source": [
    "# Define directories\n",
    "root_dir = '/content/drive/MyDrive/Task2/Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "# Define dataset transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(X_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZM7a6N1Rh3V"
   },
   "outputs": [],
   "source": [
    "# Define custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.hazy_dir = os.path.join(root_dir, 'hazy')\n",
    "        self.gt_dir = os.path.join(root_dir, 'GT')\n",
    "\n",
    "        # Get list of image filenames\n",
    "        self.image_filenames = sorted([filename for filename in os.listdir(self.hazy_dir) if filename.endswith(('.jpg', '.png'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_img_path = os.path.join(self.hazy_dir, self.image_filenames[idx])\n",
    "        gt_img_path = os.path.join(self.gt_dir, self.image_filenames[idx])\n",
    "\n",
    "        hazy_img = Image.open(hazy_img_path)\n",
    "        gt_img = Image.open(gt_img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            hazy_img = self.transform(hazy_img)\n",
    "            gt_img = self.transform(gt_img)\n",
    "\n",
    "        return hazy_img, gt_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0Elrrc2Rk0r"
   },
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomDataset(train_dir, transform)\n",
    "val_dataset = CustomDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "qnL5ZZLDSBIU",
    "outputId": "cf7d4b87-a534-4283-b742-805d43dc204f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Get a batch of data from the dataloader\n",
    "hazy_batch, gt_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Visualize a few samples\n",
    "num_samples = 5\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(num_samples):\n",
    "    # Plot hazy image\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    plt.imshow(hazy_batch[i].permute(1, 2, 0))  # Permute dimensions for visualization\n",
    "    plt.title(\"Hazy Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot ground truth image\n",
    "    plt.subplot(2, num_samples, i + num_samples + 1)\n",
    "    plt.imshow(gt_batch[i].permute(1, 2, 0))  # Permute dimensions for visualization\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg8EY8JhRo3v"
   },
   "outputs": [],
   "source": [
    "# Define the generator and discriminator networks\n",
    "# You need to define your Generator and Discriminator architectures here\n",
    "# Example:\n",
    "# generator = Generator()\n",
    "# discriminator = Discriminator()\n",
    "\n",
    "# Define the conditional GAN model\n",
    "class ConditionalGAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, hazy_imgs):\n",
    "        # Generate dehazed images\n",
    "        dehazed_imgs = self.generator(hazy_imgs)\n",
    "        return dehazed_imgs\n",
    "\n",
    "# Initialize networks and other hyperparameters\n",
    "# Define your generator and discriminator networks and other hyperparameters here\n",
    "# Example:\n",
    "# generator = Generator()\n",
    "# discriminator = Discriminator()\n",
    "# criterion_adv = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "# criterion_content = nn.L1Loss()  # L1 loss for content similarity\n",
    "# optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define loss functions (adversarial loss, content loss, etc.)\n",
    "# Example:\n",
    "# adversarial_loss = nn.BCELoss()\n",
    "# content_loss = nn.L1Loss()\n",
    "\n",
    "# Define optimizers (e.g., Adam optimizer)\n",
    "# Example:\n",
    "# optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop\n",
    "def train(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (hazy_imgs, gt_imgs) in enumerate(train_dataloader):\n",
    "            # Transfer data to GPU if available\n",
    "            hazy_imgs = hazy_imgs.to(device)\n",
    "            gt_imgs = gt_imgs.to(device)\n",
    "\n",
    "            # Train the generator\n",
    "            # Example:\n",
    "            # optimizer_G.zero_grad()\n",
    "            # fake_imgs = generator(hazy_imgs)\n",
    "            # g_loss = adversarial_loss(discriminator(fake_imgs), torch.ones_like(fake_imgs))\n",
    "            # g_loss.backward()\n",
    "            # optimizer_G.step()\n",
    "\n",
    "            # Train the discriminator\n",
    "            # Example:\n",
    "            # optimizer_D.zero_grad()\n",
    "            # real_loss = adversarial_loss(discriminator(gt_imgs), torch.ones_like(gt_imgs))\n",
    "            # fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), torch.zeros_like(fake_imgs))\n",
    "            # d_loss = (real_loss + fake_loss) / 2\n",
    "            # d_loss.backward()\n",
    "            # optimizer_D.step()\n",
    "\n",
    "            # Print training stats (loss, etc.) every few batches\n",
    "\n",
    "        # Validate the model on the validation set after each epoch\n",
    "        # Implement validation code to evaluate the model performance\n",
    "\n",
    "        # Save checkpoints of the model if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joKT-JarRp-B"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "train(num_epochs=10)  # Specify the number of epochs you want to train for\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
