{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GET AVERAGE/MEDIAN PSNR SCORE & SIMILARITY SCORE ON VALIDATION DATASET FOR ANY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from database2 import DehazingDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# FOR PSNR/SSIM\n",
    "import numpy as np\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchvision.transforms import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# SIMPLE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        # Perform global average pooling\n",
    "        x = torch.mean(x, dim=(2, 3))\n",
    "        return torch.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# REFERENCED REPO MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, stride = 2):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,4,stride,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels = 3, features = [64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2,features[0],kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        ) # according to paper 64 channel doesn't contain BatchNorm2d\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(CNNBlock(in_channels,feature,stride=1 if feature==features[-1] else 2 ))\n",
    "            in_channels = feature\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode='reflect')\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        x = torch.cat([x,y],dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x, y)\n",
    "    print(model)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, down = True, act = 'relu', use_dropout = False):\n",
    "        super(Block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False,padding_mode='reflect')\n",
    "            if down\n",
    "            else\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features,4,2,1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features,features*2,down=True,act='leaky',use_dropout=False)\n",
    "        self.down2 = Block(features*2,features*4,down=True,act='leaky',use_dropout=False)\n",
    "        self.down3 = Block(features*4,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down4 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down5 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down6 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up2 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up3 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up4 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=False)\n",
    "        self.up5 = Block(features*8*2,features*4,down=False,act='relu',use_dropout=False)\n",
    "        self.up6 = Block(features*4*2,features*2,down=False,act='relu',use_dropout=False)\n",
    "        self.up7 = Block(features*2*2,features,down=False,act='relu',use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2,in_channels,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1,d7],dim=1))\n",
    "        up3 = self.up3(torch.cat([up2,d6],dim=1))\n",
    "        up4 = self.up4(torch.cat([up3,d5],dim=1))\n",
    "        up5 = self.up5(torch.cat([up4,d4],dim=1))\n",
    "        up6 = self.up6(torch.cat([up5,d3],dim=1))\n",
    "        up7 = self.up7(torch.cat([up6,d2],dim=1))\n",
    "        return self.final_up(torch.cat([up7,d1],dim=1))\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    model = Generator(in_channels=3, features=64)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# SIMPLE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act='relu'):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect') if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == 'relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features*2, down=True)\n",
    "        self.down2 = Block(features*2, features*4, down=True)\n",
    "        self.down3 = Block(features*4, features*8, down=True)\n",
    "        self.down4 = Block(features*8, features*8, down=True)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8, features*8, down=False)\n",
    "        self.up2 = Block(features*8*2, features*8, down=False)\n",
    "        self.up3 = Block(features*8*2, features*4, down=False)\n",
    "        self.up4 = Block(features*4*2, features*2, down=False)\n",
    "        self.up5 = Block(features*2*2, features, down=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        bottleneck = self.bottleneck(d5)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d5], dim=1))\n",
    "        up3 = self.up3(torch.cat([up2, d4], dim=1))\n",
    "        up4 = self.up4(torch.cat([up3, d3], dim=1))\n",
    "        up5 = self.up5(torch.cat([up4, d2], dim=1))\n",
    "        return self.final_up(torch.cat([up5, d1], dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Baseline Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicGenerator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# MODEL - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "def up_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.ReLU(inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "class GeneratorModel4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorModel4, self).__init__()\n",
    "        # Encoding layers\n",
    "        self.down_conv_1 = down_conv(3,64,5,1,2)\n",
    "        self.down_conv_2 = down_conv(64,128,4,2,1)\n",
    "        self.down_conv_3 = down_conv(128,256,4,2,1)\n",
    "        self.down_conv_4 = down_conv(256,512,4,2,1)\n",
    "\n",
    "        self.up_trans_3 = up_conv(256, 128, 4, 2, 1)\n",
    "        self.up_conv_3 = down_conv(256, 128, 3, 1, 1)\n",
    "        self.up_trans_4 = up_conv(128, 64, 4, 2, 1)\n",
    "        self.up_conv_4 = down_conv(128, 64, 3, 1, 1)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "      #encoder\n",
    "                                   # image = [32, 3, 256, 256]\n",
    "      x1 = self.down_conv_1(image) # x1 = [32, 64, 256, 256]\n",
    "      x2 = self.down_conv_2(x1)    # x2 = [32, 128, 128, 128]\n",
    "      x3 = self.down_conv_3(x2)    # x3 = [32, 256, 64, 64]\n",
    "\n",
    "      #decoder\n",
    "      y = self.up_trans_3(x3)                   # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_conv_3(torch.cat([y,x2],1))  # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_trans_4(y)                   # y4 = [32, 64, 256, 256]\n",
    "      y = self.up_conv_4(torch.cat([y,x1],1))  # y4 = [32, 64, 256, 256]\n",
    "      y = self.out(y)\n",
    "\n",
    "      return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# MODEL - 5; HEAVY RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "def up_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.ReLU(inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "class GeneratorModel5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorModel5, self).__init__()\n",
    "        # Encoding layers\n",
    "        self.down_conv_1 = down_conv(3,64,5,1,2)\n",
    "        self.down_conv_2 = down_conv(64,128,4,2,1)\n",
    "        self.down_conv_3 = down_conv(128,256,4,2,1)\n",
    "        self.down_conv_4 = down_conv(256,512,4,2,1)\n",
    "        self.down_conv_5 = down_conv(512,1024,4,2,1)\n",
    "\n",
    "        self.up_trans_1 = up_conv(1024, 512, 4, 2, 1)\n",
    "        self.up_conv_1 = down_conv(1024,512, 3, 1, 1)\n",
    "        self.up_trans_2 = up_conv(512, 256, 4, 2, 1)\n",
    "        self.up_conv_2 = down_conv(512, 256, 3, 1, 1)\n",
    "        self.up_trans_3 = up_conv(256, 128, 4, 2, 1)\n",
    "        self.up_conv_3 = down_conv(256, 128, 3, 1, 1)\n",
    "        self.up_trans_4 = up_conv(128, 64, 4, 2, 1)\n",
    "        self.up_conv_4 = down_conv(128, 64, 3, 1, 1)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "      #encoder\n",
    "                                   # image = [32, 3, 256, 256]\n",
    "      x1 = self.down_conv_1(image) # x1 = [32, 64, 256, 256]\n",
    "      x2 = self.down_conv_2(x1)    # x2 = [32, 128, 128, 128]\n",
    "      x3 = self.down_conv_3(x2)    # x3 = [32, 256, 64, 64]\n",
    "      x4 = self.down_conv_4(x3)    # x4 = [32, 512, 32, 32]\n",
    "      x5 = self.down_conv_5(x4)    # x5 = [32, 1024, 16, 16]\n",
    "\n",
    "      #decoder\n",
    "      y = self.up_trans_1(x5)                   # y1 = [32, 512, 32, 32]\n",
    "      y = self.up_conv_1(torch.cat([y,x4],1))  # y1 = [32, 512, 32, 32]\n",
    "      y = self.up_trans_2(y)                   # y2 = [32, 256, 64, 64]\n",
    "      y = self.up_conv_2(torch.cat([y,x3],1))  # y2 = [32, 256, 64, 64]\n",
    "      y = self.up_trans_3(y)                   # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_conv_3(torch.cat([y,x2],1))  # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_trans_4(y)                   # y4 = [32, 64, 256, 256]\n",
    "      y = self.up_conv_4(torch.cat([y,x1],1))  # y4 = [32, 64, 256, 256]\n",
    "      y = self.out(y)\n",
    "\n",
    "      return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO CREATE DATALOADERS\n",
    "\n",
    "def custom_transform(x):\n",
    "    return x / torch.max(x.abs())\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloader(directory, batch_size=32, mean=0.5, std=0.5):\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.ToTensor(),   \n",
    "    #     transforms.Normalize(mean=mean, std=std)\n",
    "    # ])\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize images\n",
    "        transforms.ToTensor(),           # Convert to tensor\n",
    "        custom_transform                  # Using the custom transform function\n",
    "    ])\n",
    "\n",
    "    dataset = DehazingDataset(directory, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    return dataloader\n",
    "\n",
    "def create_train_val_dataloaders(root_dir, train_batch_size=32, val_batch_size=32, mean=0.5, std=0.5):\n",
    "    train_dir = os.path.join(root_dir, 'train')\n",
    "    val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "    train_dataloader = create_dataloader(train_dir, batch_size=train_batch_size, mean=mean, std=std)\n",
    "    val_dataloader = create_dataloader(val_dir, batch_size=val_batch_size, mean=mean, std=std)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHERE VAL AND TRAIN FOLDERS ARE PRESENT\n",
    "root_dir = '../Task2Dataset'\n",
    "train_dataloader, val_dataloader = create_train_val_dataloaders(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "std1 = 0.5\n",
    "std2 = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "mean1 = 0.5\n",
    "mean2 = np.array([0.485, 0.456, 0.406])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(hazy_imgs, clean_imgs, generated_imgs, mean, std, num_images=5, save_path = None):\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        clean_image = clean_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        hazy_image = hazy_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        generated_image = generated_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "\n",
    "        clean_image = clean_image * mean + std\n",
    "        hazy_image = hazy_image * mean + std\n",
    "        # generated_image = generated_image * mean + std\n",
    "\n",
    "        \n",
    "        # Plot hazy images\n",
    "        axes[0, i].imshow(hazy_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Hazy Image\")\n",
    "\n",
    "        # Plot clean images\n",
    "        axes[1, i].imshow(clean_image)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Clean Image\")\n",
    "\n",
    "        # Plot generated images\n",
    "        axes[2, i].imshow(generated_image)\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(\"Generated Image\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE AND LOAD WEIGHTS TO A GENERATOR\n",
    "\n",
    "def load_generator_weights(generator, weights_path):\n",
    "    map_location = torch.device('cpu')\n",
    "    generator.load_state_dict(torch.load(weights_path, map_location=map_location))\n",
    "    generator.eval()\n",
    "\n",
    "    return generator\n",
    "    \n",
    "\n",
    "generator = GeneratorModel4()\n",
    "\n",
    "weights_path = '../Models/generator_epoch_4.pth'\n",
    "\n",
    "generator = load_generator_weights(generator, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_images_from_dataloader(val_dataloader, total_images = 40):\n",
    "    count = 0\n",
    "    for hazy_imgs, clean_imgs in val_dataloader:\n",
    "        generated_imgs = generator(hazy_imgs)\n",
    "        show_images(hazy_imgs, clean_imgs, generated_imgs, num_images = 5 )\n",
    "        count += 5\n",
    "\n",
    "        if count >= total_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO GET MEAN/MEDIAN PSNR SCORES AND SIMILARITY\n",
    "def PSNR(img1, img2):\n",
    "    \"\"\"Calculate the Peak Signal-to-Noise Ratio (PSNR) between two images.\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:  \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 10 * log10(max_pixel**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "def compute_PSNR(imgs1, imgs2):\n",
    "    \"\"\"Calculate PSNR for a batch of images.\"\"\"\n",
    "    psnr_scores = []\n",
    "    for img1, img2 in zip(imgs1, imgs2):\n",
    "        img1_np = img1.detach().cpu().numpy()\n",
    "        img2_np = img2.detach().cpu().numpy()\n",
    "        psnr_scores.append(PSNR(img1_np, img2_np))\n",
    "    return psnr_scores\n",
    "\n",
    "def compute_SSIM(imgs1, imgs2):\n",
    "    \"\"\"Calculate SSIM for a batch of images.\"\"\"\n",
    "    ssim_scores = []\n",
    "    for img1, img2 in zip(imgs1, imgs2):\n",
    "        img1_np = img1.detach().cpu().numpy()\n",
    "        img2_np = img2.detach().cpu().numpy()\n",
    "        \n",
    "        # Resize images if they are too small\n",
    "        min_size = min(img1_np.shape[0], img1_np.shape[1])\n",
    "        if min_size < 7:\n",
    "            ratio = 7 / min_size\n",
    "            img1_np = resize(img1_np, (int(img1_np.shape[0] * ratio), int(img1_np.shape[1] * ratio)))\n",
    "            img2_np = resize(img2_np, (int(img2_np.shape[0] * ratio), int(img2_np.shape[1] * ratio)))\n",
    "        \n",
    "        ssim_scores.append(ssim(img1_np, img2_np, multichannel=True, data_range=1))\n",
    "    return ssim_scores\n",
    "\n",
    "\n",
    "def get_mean_score(scores):\n",
    "    \"\"\"Calculate the mean score from a list of scores.\"\"\"\n",
    "    mean_score = np.mean(scores)\n",
    "    return mean_score\n",
    "\n",
    "def get_median_score(scores):\n",
    "    \"\"\"Calculate the median score from a list of scores.\"\"\"\n",
    "    median_score = np.median(scores)\n",
    "    return median_score\n",
    "\n",
    "def denormalize(img, mean=0.5, std=0.5):\n",
    "    \"\"\"Denormalize a single image.\"\"\"\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    denormalized_img = img * std + mean\n",
    "    return denormalized_img\n",
    "\n",
    "def print_scores(val_dataloader, generator, mean=0.5, std=0.5):\n",
    "    psnr_scores = []\n",
    "    ssim_scores = []\n",
    "    i = 1\n",
    "    for hazy_imgs, clean_imgs in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            generated_imgs = generator(hazy_imgs)\n",
    "        # generated_imgs = denormalize(generated_imgs, mean, std)\n",
    "        # clean_imgs = denormalize(clean_imgs, mean, std)\n",
    "        generated_imgs = generated_imgs * 255\n",
    "        clean_imgs = clean_imgs * 255\n",
    "        psnr_batch = compute_PSNR(clean_imgs, generated_imgs)\n",
    "        ssim_batch = compute_SSIM(clean_imgs, generated_imgs)\n",
    "        psnr_scores.extend(psnr_batch)\n",
    "        ssim_scores.extend(ssim_batch)\n",
    "\n",
    "        print(f\"{i}th Batch Done\")\n",
    "        i += 1\n",
    "\n",
    "    mean_psnr = get_mean_score(psnr_scores)\n",
    "    median_psnr = get_median_score(psnr_scores)\n",
    "    mean_ssim = get_mean_score(ssim_scores)\n",
    "    median_ssim = get_median_score(ssim_scores)\n",
    "\n",
    "    print(f\"Mean PSNR: {mean_psnr:.2f}, Median PSNR: {median_psnr:.2f}\")\n",
    "    print(f\"Mean SSIM: {mean_ssim:.4f}, Median SSIM: {median_ssim:.4f}\")\n",
    "\n",
    "    return psnr_scores, ssim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_scores, ssim_scores = print_scores(val_dataloader, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(psnr_scores), np.min(psnr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(ssim_scores), np.min(ssim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
