{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from database2 import DehazingDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from torchvision.transforms import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        # Perform global average pooling\n",
    "        x = torch.mean(x, dim=(2, 3))\n",
    "        return torch.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, stride = 2):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,4,stride,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels = 3, features = [64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2,features[0],kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        ) # according to paper 64 channel doesn't contain BatchNorm2d\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(CNNBlock(in_channels,feature,stride=1 if feature==features[-1] else 2 ))\n",
    "            in_channels = feature\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode='reflect')\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        x = torch.cat([x,y],dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x, y)\n",
    "    print(model)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, down = True, act = 'relu', use_dropout = False):\n",
    "        super(Block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False,padding_mode='reflect')\n",
    "            if down\n",
    "            else\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features,4,2,1,padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features,features*2,down=True,act='leaky',use_dropout=False)\n",
    "        self.down2 = Block(features*2,features*4,down=True,act='leaky',use_dropout=False)\n",
    "        self.down3 = Block(features*4,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down4 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down5 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.down6 = Block(features*8,features*8,down=True,act='leaky',use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up2 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up3 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=True)\n",
    "        self.up4 = Block(features*8*2,features*8,down=False,act='relu',use_dropout=False)\n",
    "        self.up5 = Block(features*8*2,features*4,down=False,act='relu',use_dropout=False)\n",
    "        self.up6 = Block(features*4*2,features*2,down=False,act='relu',use_dropout=False)\n",
    "        self.up7 = Block(features*2*2,features,down=False,act='relu',use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2,in_channels,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1,d7],dim=1))\n",
    "        up3 = self.up3(torch.cat([up2,d6],dim=1))\n",
    "        up4 = self.up4(torch.cat([up3,d5],dim=1))\n",
    "        up5 = self.up5(torch.cat([up4,d4],dim=1))\n",
    "        up6 = self.up6(torch.cat([up5,d3],dim=1))\n",
    "        up7 = self.up7(torch.cat([up6,d2],dim=1))\n",
    "        return self.final_up(torch.cat([up7,d1],dim=1))\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    model = Generator(in_channels=3, features=64)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act='relu'):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect') if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == 'relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features*2, down=True)\n",
    "        self.down2 = Block(features*2, features*4, down=True)\n",
    "        self.down3 = Block(features*4, features*8, down=True)\n",
    "        self.down4 = Block(features*8, features*8, down=True)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode='reflect'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features*8, features*8, down=False)\n",
    "        self.up2 = Block(features*8*2, features*8, down=False)\n",
    "        self.up3 = Block(features*8*2, features*4, down=False)\n",
    "        self.up4 = Block(features*4*2, features*2, down=False)\n",
    "        self.up5 = Block(features*2*2, features, down=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        bottleneck = self.bottleneck(d5)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d5], dim=1))\n",
    "        up3 = self.up3(torch.cat([up2, d4], dim=1))\n",
    "        up4 = self.up4(torch.cat([up3, d3], dim=1))\n",
    "        up5 = self.up5(torch.cat([up4, d2], dim=1))\n",
    "        return self.final_up(torch.cat([up5, d1], dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "def up_conv(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  conv = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.ReLU(inplace=True)\n",
    "  )\n",
    "  return conv\n",
    "\n",
    "class GeneratorModel5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorModel5, self).__init__()\n",
    "        # Encoding layers\n",
    "        self.down_conv_1 = down_conv(3,64,5,1,2)\n",
    "        self.down_conv_2 = down_conv(64,128,4,2,1)\n",
    "        self.down_conv_3 = down_conv(128,256,4,2,1)\n",
    "        self.down_conv_4 = down_conv(256,512,4,2,1)\n",
    "        self.down_conv_5 = down_conv(512,1024,4,2,1)\n",
    "\n",
    "        self.up_trans_1 = up_conv(1024, 512, 4, 2, 1)\n",
    "        self.up_conv_1 = down_conv(1024,512, 3, 1, 1)\n",
    "        self.up_trans_2 = up_conv(512, 256, 4, 2, 1)\n",
    "        self.up_conv_2 = down_conv(512, 256, 3, 1, 1)\n",
    "        self.up_trans_3 = up_conv(256, 128, 4, 2, 1)\n",
    "        self.up_conv_3 = down_conv(256, 128, 3, 1, 1)\n",
    "        self.up_trans_4 = up_conv(128, 64, 4, 2, 1)\n",
    "        self.up_conv_4 = down_conv(128, 64, 3, 1, 1)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "      #encoder\n",
    "                                   # image = [32, 3, 256, 256]\n",
    "      x1 = self.down_conv_1(image) # x1 = [32, 64, 256, 256]\n",
    "      x2 = self.down_conv_2(x1)    # x2 = [32, 128, 128, 128]\n",
    "      x3 = self.down_conv_3(x2)    # x3 = [32, 256, 64, 64]\n",
    "      x4 = self.down_conv_4(x3)    # x4 = [32, 512, 32, 32]\n",
    "      x5 = self.down_conv_5(x4)    # x5 = [32, 1024, 16, 16]\n",
    "\n",
    "      #decoder\n",
    "      y = self.up_trans_1(x5)                   # y1 = [32, 512, 32, 32]\n",
    "      y = self.up_conv_1(torch.cat([y,x4],1))  # y1 = [32, 512, 32, 32]\n",
    "      y = self.up_trans_2(y)                   # y2 = [32, 256, 64, 64]\n",
    "      y = self.up_conv_2(torch.cat([y,x3],1))  # y2 = [32, 256, 64, 64]\n",
    "      y = self.up_trans_3(y)                   # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_conv_3(torch.cat([y,x2],1))  # y3 = [32, 128, 128, 128]\n",
    "      y = self.up_trans_4(y)                   # y4 = [32, 64, 256, 256]\n",
    "      y = self.up_conv_4(torch.cat([y,x1],1))  # y4 = [32, 64, 256, 256]\n",
    "      y = self.out(y)\n",
    "\n",
    "      return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../Task2Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),   \n",
    "#     transforms.Normalize(mean = 0.5,std = 0.5)\n",
    "# ])\n",
    "\n",
    "def custom_transform(x):\n",
    "    return x / torch.max(x.abs())\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize images\n",
    "        transforms.ToTensor(),           # Convert to tensor\n",
    "        custom_transform                  # Using the custom transform function\n",
    "    ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std1 = 0.5\n",
    "std2 = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "mean1 = 0.5\n",
    "mean2 = np.array([0.485, 0.456, 0.406])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(hazy_imgs, clean_imgs, generated_imgs, mean, std, num_images=5, save_path = None):\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        clean_image = clean_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        hazy_image = hazy_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "        generated_image = generated_imgs[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "\n",
    "        # clean_image = clean_image * mean + std\n",
    "        # hazy_image = hazy_image * mean + std\n",
    "        # generated_image = generated_image * mean + std\n",
    "\n",
    "        \n",
    "        # Plot hazy images\n",
    "        axes[0, i].imshow(hazy_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Hazy Image\")\n",
    "\n",
    "        # Plot clean images\n",
    "        axes[1, i].imshow(clean_image)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Clean Image\")\n",
    "\n",
    "        # Plot generated images\n",
    "        axes[2, i].imshow(generated_image)\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(\"Generated Image\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE AND LOAD WEIGHTS TO A GENERATOR\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "weights_path = '../Training/generator_cgan_wgan.pth'\n",
    "\n",
    "# Load the weights into the generator model\n",
    "map_location = torch.device('cpu')\n",
    "generator.load_state_dict(torch.load(weights_path, map_location=map_location))\n",
    "\n",
    "\n",
    "# Set the generator to evaluation mode\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for hazy_imgs, clean_imgs in val_dataloader:\n",
    "    generated_imgs = generator(hazy_imgs)\n",
    "    show_images(hazy_imgs, clean_imgs, generated_imgs, mean = 0.5, std = 0.5, save_path = f\"gen_model1_wgan_{count}\")\n",
    "    count += 1\n",
    "\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# NORMAL GAN - L1 LOSS AND SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_imgs = generator(hazy_imgs)\n",
    "show_images(hazy_imgs, clean_imgs, generated_imgs, mean1, std1, save_path = \"generated_gan_l1_scheduler.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# NORMAL GAN - L1 LOSS AND NO SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_imgs = generator(hazy_imgs)\n",
    "show_images(hazy_imgs, clean_imgs, generated_imgs, mean1, std1, save_path = \"generated_gan_l1_noscheduler.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# NORMAL GAN - NO L1 LOSS,NO SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_imgs = generator(hazy_imgs)\n",
    "show_images(hazy_imgs, clean_imgs, generated_imgs, mean1, std1, save_path = \"generated_basic.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# CGAN - L1 LOSS AND SCHEDULERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_imgs = generator(hazy_imgs)\n",
    "show_images(hazy_imgs, clean_imgs, generated_imgs, mean2, std2, save_path = \"generated_cgan.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
