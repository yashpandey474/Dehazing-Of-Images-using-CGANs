{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Get generated images with highest PSNR/Similarity\n",
    "\n",
    "### The higher the value of PSNR (in decibels/dB), the better the reconstruction quality\n",
    "### SSIM ranges between 0 and 1, where a higher value indicates greater structural coherence and thus better Dehazing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from database2 import DehazingDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:  \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 10 * log10(max_pixel**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "def visualize_top_images(psnr, top_x):\n",
    "    # BASED ON HIGHEST PSNR\n",
    "    if psnr == 1:\n",
    "        top_images = [generated_images[i] for i in sorted_indices_psnr[:top_x]]\n",
    "    else: # BASED ON HIGHEST SSIM\n",
    "        top_images = [generated_images[i] for i in sorted_indices_ssim[:top_x]]\n",
    "\n",
    "    fig, axes = plt.subplots(1, top_x, figsize=(15, 5))\n",
    "    for i in range(top_x):\n",
    "        image = top_images[i].transpose(1, 2, 0)\n",
    "        image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
    "        # Transpose dimensions from (3, 256, 256) to (256, 256, 3)\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Image {i+1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        \n",
    "# similarity = ssim(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Task2Dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "transform = transforms.Compose([\n",
    "                                #  transforms.Resize((224, 224)), # ASSUMING NO NEED FOR RESIZING AS ALL IMAGES ARE ALREADY 256*256\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                 ])\n",
    "\n",
    "train_dataset = DehazingDataset(train_dir, transform)\n",
    "val_dataset = DehazingDataset(val_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE AND LOAD WEIGHTS TO A GENERATOR\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "weights_path = 'generator_l1loss_scheduler.pth'\n",
    "\n",
    "# Load the weights into the generator model\n",
    "generator.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "# Set the generator to evaluation mode\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Iterate through hazy images and compute PSNR or SSIM for each generated image\n",
    "psnr_scores = []\n",
    "ssim_scores = []\n",
    "generated_images = []\n",
    "\n",
    "for hazy_imgs, clean_imgs in tqdm(train_dataloader, desc='Computing Metrics'):\n",
    "    # Generate images using your GAN model (replace this with your GAN inference code)\n",
    "    generated_imgs = generator(hazy_imgs)\n",
    "    \n",
    "    # Compute PSNR and SSIM for each pair of generated and clean images in the batch\n",
    "    for generated_img, clean_img in zip(generated_imgs, clean_imgs):\n",
    "        # Convert tensors to numpy arrays\n",
    "        generated_img_np = generated_img.detach().cpu().numpy()\n",
    "        clean_img_np = clean_img.detach().cpu().numpy()\n",
    "\n",
    "        clean_image = images[i].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "        clean_image = clean_image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
    "        \n",
    "\n",
    "        # Store for later visualisation\n",
    "        generated_images.append(generated_img_np)\n",
    "        \n",
    "        # Compute PSNR\n",
    "        psnr = PSNR(generated_img_np, clean_img_np)\n",
    "        psnr_scores.append(psnr)\n",
    "        \n",
    "        # Compute SSIM\n",
    "        # resized_generated_img_np = resize(generated_img_np, clean_img_np.shape)\n",
    "        # ssimilarity = ssim(resized_generated_img_np, clean_img_np, multichannel=True)\n",
    "        # ssim_scores.append(ssimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.amin(clean_img_np)\n",
    "max_value = np.amax(clean_img_np)\n",
    "\n",
    "print(\"Minimum pixel value:\", min_value)\n",
    "print(\"Maximum pixel value:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.amin(generated_img_np)\n",
    "max_value = np.amax(generated_img_np)\n",
    "\n",
    "print(\"Minimum pixel value:\", min_value)\n",
    "print(\"Maximum pixel value:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort generated images based on PSNR or SSIM scores\n",
    "# Choose PSNR or SSIM as per your requirement\n",
    "sorted_indices_psnr = np.argsort(psnr_scores)[::-1]  # Sort in descending order\n",
    "# sorted_indices_ssim = np.argsort(ssim_scores)[::-1]  # Sort in descending order\n",
    "\n",
    "# Visualize top X images based on PSNR or SSIM\n",
    "top_x = 5  # Change this value as needed\n",
    "visualize_top_images(1, top_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(hazy_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(generator(hazy_imgs)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clean_imgs[0].detach().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_image = clean_imgs[1].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "clean_image = clean_image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
    "plt.imshow(clean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_image = generator(hazy_imgs)[1].detach().permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "clean_image = clean_image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
    "plt.imshow(clean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(psnr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_image = images[i].permute(1, 2, 0).cpu().numpy()  # Convert to NumPy array\n",
    "clean_image = clean_image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
